{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting embedchain\n",
      "  Obtaining dependency information for embedchain from https://files.pythonhosted.org/packages/1c/52/19b320d0bfda484c092b2371de178593f6fc80700932927836c66d17a538/embedchain-0.0.92-py3-none-any.whl.metadata\n",
      "  Downloading embedchain-0.0.92-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting chromadb<0.5.0,>=0.4.8 (from embedchain)\n",
      "  Obtaining dependency information for chromadb<0.5.0,>=0.4.8 from https://files.pythonhosted.org/packages/f8/d5/fdff4ceb41e322aac8dae71e005c263750b096b9bd39e4dab784377817a3/chromadb-0.4.16-py3-none-any.whl.metadata\n",
      "  Downloading chromadb-0.4.16-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting langchain<0.0.304,>=0.0.303 (from embedchain)\n",
      "  Obtaining dependency information for langchain<0.0.304,>=0.0.303 from https://files.pythonhosted.org/packages/76/5c/c00a01d1652f260d462370eeba3019bf97100e6b3b72120cacbe92410394/langchain-0.0.303-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.0.303-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting openai>=0.28.0 (from embedchain)\n",
      "  Obtaining dependency information for openai>=0.28.0 from https://files.pythonhosted.org/packages/42/9d/b227c396c6eafbece9a8fe877379582481b108c0c0cf4ff8770ce63926ad/openai-1.2.0-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting posthog<4.0.0,>=3.0.2 (from embedchain)\n",
      "  Obtaining dependency information for posthog<4.0.0,>=3.0.2 from https://files.pythonhosted.org/packages/a7/73/35758818228c70348be4c3c66a76653c62e894e0e3c3461453c5341ca926/posthog-3.0.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading posthog-3.0.2-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /opt/homebrew/lib/python3.11/site-packages (from embedchain) (1.0.0)\n",
      "Collecting schema<0.8.0,>=0.7.5 (from embedchain)\n",
      "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: tiktoken<0.5.0,>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from embedchain) (0.4.0)\n",
      "Collecting youtube-transcript-api<0.7.0,>=0.6.1 (from embedchain)\n",
      "  Obtaining dependency information for youtube-transcript-api<0.7.0,>=0.6.1 from https://files.pythonhosted.org/packages/33/c1/18e32c7cd693802056f385c3ee78825102566be94a811b6556f17783c743/youtube_transcript_api-0.6.1-py3-none-any.whl.metadata\n",
      "  Downloading youtube_transcript_api-0.6.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: requests>=2.28 in /opt/homebrew/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.8->embedchain) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in /opt/homebrew/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.8->embedchain) (1.10.11)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for chroma-hnswlib==0.7.3 from https://files.pythonhosted.org/packages/11/7a/673ccb9bb2faf9cf655d9040e970c02a96645966e06837fde7d10edf242a/chroma_hnswlib-0.7.3-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading chroma_hnswlib-0.7.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (252 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for fastapi>=0.95.2 from https://files.pythonhosted.org/packages/f3/4f/0ce34195b63240b6693086496c9bab4ef23999112184399a3e88854c7674/fastapi-0.104.1-py3-none-any.whl.metadata\n",
      "  Downloading fastapi-0.104.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting uvicorn[standard]>=0.18.3 (from chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for uvicorn[standard]>=0.18.3 from https://files.pythonhosted.org/packages/7e/17/4b7a76fffa7babf397481040d8aef2725b2b81ae19f1a31b5ca0c17d49e6/uvicorn-0.24.0.post1-py3-none-any.whl.metadata\n",
      "  Downloading uvicorn-0.24.0.post1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/homebrew/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.8->embedchain) (4.7.1)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for pulsar-client>=3.1.0 from https://files.pythonhosted.org/packages/2d/b1/e7fa626abe03ba5a2a8d52ed05ebc6ff2ab6b13b771f05d8175feabfa17b/pulsar_client-3.3.0-cp311-cp311-macosx_10_15_universal2.whl.metadata\n",
      "  Downloading pulsar_client-3.3.0-cp311-cp311-macosx_10_15_universal2.whl.metadata (1.0 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for onnxruntime>=1.14.1 from https://files.pythonhosted.org/packages/6b/4a/fda588a7a296fa0a5b1618d7de7a1be583125b7f6616463618a092c613de/onnxruntime-1.16.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading onnxruntime-1.16.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for opentelemetry-api>=1.2.0 from https://files.pythonhosted.org/packages/51/3a/945e6c21f405ac4ea526f91ee09cc1568c04e0c95d3392903e6984c8f0e0/opentelemetry_api-1.21.0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_api-1.21.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for opentelemetry-exporter-otlp-proto-grpc>=1.2.0 from https://files.pythonhosted.org/packages/75/59/ec3e39fe164c61306998cdd3cd30a857c4da2f8d3141204a929e57668eee/opentelemetry_exporter_otlp_proto_grpc-1.21.0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.21.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for opentelemetry-sdk>=1.2.0 from https://files.pythonhosted.org/packages/c3/08/ca8b1ef7a2fa3f1ea2f12770eca8976098066adb442b1da81fea3b370123/opentelemetry_sdk-1.21.0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_sdk-1.21.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /opt/homebrew/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.8->embedchain) (0.13.3)\n",
      "Collecting pypika>=0.48.9 (from chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Using cached PyPika-0.48.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /opt/homebrew/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.8->embedchain) (4.65.0)\n",
      "Collecting overrides>=7.3.1 (from chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for overrides>=7.3.1 from https://files.pythonhosted.org/packages/da/28/3fa6ef8297302fc7b3844980b6c5dbc71cdbd4b61e9b2591234214d5ab39/overrides-7.4.0-py3-none-any.whl.metadata\n",
      "  Downloading overrides-7.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting importlib-resources (from chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for importlib-resources from https://files.pythonhosted.org/packages/93/e8/facde510585869b5ec694e8e0363ffe4eba067cb357a8398a55f6a1f8023/importlib_resources-6.1.1-py3-none-any.whl.metadata\n",
      "  Downloading importlib_resources-6.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/homebrew/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.8->embedchain) (1.59.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Downloading bcrypt-4.0.1-cp36-abi3-macosx_10_10_universal2.whl (473 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.4/473.4 kB\u001b[0m \u001b[31m508.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting typer>=0.9.0 (from chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kubernetes>=28.1.0 (from chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for kubernetes>=28.1.0 from https://files.pythonhosted.org/packages/f5/6a/1f69c2d8b1ff03f8d8e10d801f4ac3016ed4c1b00aa9795732c6ec900bba/kubernetes-28.1.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading kubernetes-28.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tenacity>=8.2.3 (from chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for tenacity>=8.2.3 from https://files.pythonhosted.org/packages/f4/f1/990741d5bb2487d529d20a433210ffa136a367751e454214013b441c4575/tenacity-8.2.3-py3-none-any.whl.metadata\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /opt/homebrew/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.8->embedchain) (6.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /opt/homebrew/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.8->embedchain) (1.25.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/lib/python3.11/site-packages (from langchain<0.0.304,>=0.0.303->embedchain) (2.0.18)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/homebrew/lib/python3.11/site-packages (from langchain<0.0.304,>=0.0.303->embedchain) (3.8.4)\n",
      "Requirement already satisfied: anyio<4.0 in /opt/homebrew/lib/python3.11/site-packages (from langchain<0.0.304,>=0.0.303->embedchain) (3.7.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/homebrew/lib/python3.11/site-packages (from langchain<0.0.304,>=0.0.303->embedchain) (0.5.9)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain<0.0.304,>=0.0.303->embedchain)\n",
      "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.38 (from langchain<0.0.304,>=0.0.303->embedchain)\n",
      "  Obtaining dependency information for langsmith<0.1.0,>=0.0.38 from https://files.pythonhosted.org/packages/d2/06/24590a71b497f0fc52f4001057c7c6149e008157b2332c5b0a4c5499f7d7/langsmith-0.0.62-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.0.62-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/homebrew/lib/python3.11/site-packages (from langchain<0.0.304,>=0.0.303->embedchain) (2.8.4)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/lib/python3.11/site-packages (from openai>=0.28.0->embedchain) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/lib/python3.11/site-packages (from openai>=0.28.0->embedchain) (0.24.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from posthog<4.0.0,>=3.0.2->embedchain) (1.16.0)\n",
      "Collecting monotonic>=1.5 (from posthog<4.0.0,>=3.0.2->embedchain)\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/homebrew/lib/python3.11/site-packages (from posthog<4.0.0,>=3.0.2->embedchain) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>2.1 in /Users/ojas/Library/Python/3.11/lib/python/site-packages (from posthog<4.0.0,>=3.0.2->embedchain) (2.8.2)\n",
      "Collecting contextlib2>=0.5.5 (from schema<0.8.0,>=0.7.5->embedchain)\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/homebrew/lib/python3.11/site-packages (from tiktoken<0.5.0,>=0.4.0->embedchain) (2023.6.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.304,>=0.0.303->embedchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.304,>=0.0.303->embedchain) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.304,>=0.0.303->embedchain) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.304,>=0.0.303->embedchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.304,>=0.0.303->embedchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.304,>=0.0.303->embedchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.304,>=0.0.303->embedchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/lib/python3.11/site-packages (from anyio<4.0->langchain<0.0.304,>=0.0.303->embedchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/lib/python3.11/site-packages (from anyio<4.0->langchain<0.0.304,>=0.0.303->embedchain) (1.3.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /opt/homebrew/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.0.304,>=0.0.303->embedchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /opt/homebrew/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.0.304,>=0.0.303->embedchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.0.304,>=0.0.303->embedchain) (0.9.0)\n",
      "Collecting starlette<0.28.0,>=0.27.0 (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for starlette<0.28.0,>=0.27.0 from https://files.pythonhosted.org/packages/58/f8/e2cca22387965584a409795913b774235752be4176d276714e15e1a58884/starlette-0.27.0-py3-none-any.whl.metadata\n",
      "  Using cached starlette-0.27.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting typing-extensions>=4.5.0 (from chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for typing-extensions>=4.5.0 from https://files.pythonhosted.org/packages/24/21/7d397a4b7934ff4028987914ac1044d3b7d52712f30e2ac7a2ae5bc86dd0/typing_extensions-4.8.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=0.28.0->embedchain) (2023.5.7)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /opt/homebrew/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=0.28.0->embedchain) (0.17.3)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain<0.0.304,>=0.0.303->embedchain)\n",
      "  Obtaining dependency information for jsonpointer>=1.9 from https://files.pythonhosted.org/packages/12/f6/0232cc0c617e195f06f810534d00b74d2f348fe71b2118009ad8ad31f878/jsonpointer-2.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.8->embedchain) (2.23.3)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 from https://files.pythonhosted.org/packages/c4/3c/1892ce394828c43d4f65248ebdee3854114266b75d1f5915cb211155ad7b/websocket_client-1.6.4-py3-none-any.whl.metadata\n",
      "  Downloading websocket_client-1.6.4-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/homebrew/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.8->embedchain) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/homebrew/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.8->embedchain) (3.2.2)\n",
      "Requirement already satisfied: urllib3<2.0,>=1.24.2 in /opt/homebrew/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.8->embedchain) (1.26.16)\n",
      "Collecting pytest-subtests<0.12.0,>=0.11.0 (from langsmith<0.1.0,>=0.0.38->langchain<0.0.304,>=0.0.303->embedchain)\n",
      "  Obtaining dependency information for pytest-subtests<0.12.0,>=0.11.0 from https://files.pythonhosted.org/packages/8a/98/50ac2d1344b0c43b81f886171e5ecf51a27fd02b32f787862f76fd7779dc/pytest_subtests-0.11.0-py3-none-any.whl.metadata\n",
      "  Downloading pytest_subtests-0.11.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for flatbuffers from https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.8->embedchain) (23.1)\n",
      "Requirement already satisfied: protobuf in /opt/homebrew/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.8->embedchain) (4.24.4)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.8->embedchain) (1.12)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for deprecated>=1.2.6 from https://files.pythonhosted.org/packages/20/8d/778b7d51b981a96554f29136cd59ca7880bf58094338085bcf2a979a0e6a/Deprecated-1.2.14-py2.py3-none-any.whl.metadata\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting importlib-metadata<7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for importlib-metadata<7.0,>=6.0 from https://files.pythonhosted.org/packages/cc/37/db7ba97e676af155f5fcb1a35466f446eadc9104e25b83366e8088c9c926/importlib_metadata-6.8.0-py3-none-any.whl.metadata\n",
      "  Downloading importlib_metadata-6.8.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/homebrew/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.8->embedchain) (1.61.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.21.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for opentelemetry-exporter-otlp-proto-common==1.21.0 from https://files.pythonhosted.org/packages/2a/60/ec618caf8fd8a4ac50500565eb49038ec42b7b168df9a316494085a740a6/opentelemetry_exporter_otlp_proto_common-1.21.0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.21.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.21.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for opentelemetry-proto==1.21.0 from https://files.pythonhosted.org/packages/69/c2/d11b5fbf95adf68440ff4c953e2d8d027c9c62ece79b78372af95af590c9/opentelemetry_proto-1.21.0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_proto-1.21.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.42b0 (from opentelemetry-sdk>=1.2.0->chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for opentelemetry-semantic-conventions==0.42b0 from https://files.pythonhosted.org/packages/c3/0c/4c99cbe85b65fbba5a638cb7d913cb3acead3d83b4c47763be28d418bb95/opentelemetry_semantic_conventions-0.42b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_semantic_conventions-0.42b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/homebrew/lib/python3.11/site-packages (from typer>=0.9.0->chromadb<0.5.0,>=0.4.8->embedchain) (8.1.4)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/homebrew/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.8->embedchain) (0.14.0)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for httptools>=0.5.0 from https://files.pythonhosted.org/packages/f5/d1/53283b96ed823d5e4d89ee9aa0f29df5a1bdf67f148e061549a595d534e4/httptools-0.6.1-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading httptools-0.6.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.6 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for uvloop!=0.15.0,!=0.15.1,>=0.14.0 from https://files.pythonhosted.org/packages/41/2a/608ad69f27f51280098abee440c33e921d3ad203e2c86f7262e241e49c99/uvloop-0.19.0-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading uvloop-0.19.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for watchfiles>=0.13 from https://files.pythonhosted.org/packages/a3/87/6793ac60d2e20c9c1883aec7431c2e7b501ee44a839f6da1b747c13baa23/watchfiles-0.21.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading watchfiles-0.21.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for websockets>=10.4 from https://files.pythonhosted.org/packages/95/aa/75fa3b893142d6d98a48cb461169bd268141f2da8bfca97392d6462a02eb/websockets-12.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading websockets-12.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Using cached wrapt-1.15.0-cp311-cp311-macosx_11_0_arm64.whl (36 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.8->embedchain) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/homebrew/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.8->embedchain) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/homebrew/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.8->embedchain) (4.9)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Obtaining dependency information for zipp>=0.5 from https://files.pythonhosted.org/packages/d9/66/48866fc6b158c81cc2bfecc04c480f105c6040e8b077bc54c634b4a67926/zipp-3.17.0-py3-none-any.whl.metadata\n",
      "  Downloading zipp-3.17.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting pytest>=7.0 (from pytest-subtests<0.12.0,>=0.11.0->langsmith<0.1.0,>=0.0.38->langchain<0.0.304,>=0.0.303->embedchain)\n",
      "  Obtaining dependency information for pytest>=7.0 from https://files.pythonhosted.org/packages/f3/8c/f16efd81ca8e293b2cc78f111190a79ee539d0d5d36ccd49975cb3beac60/pytest-7.4.3-py3-none-any.whl.metadata\n",
      "  Downloading pytest-7.4.3-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/lib/python3.11/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.0.304,>=0.0.303->embedchain) (1.0.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.8->embedchain)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.8->embedchain) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/homebrew/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.8->embedchain) (0.5.0)\n",
      "Collecting iniconfig (from pytest>=7.0->pytest-subtests<0.12.0,>=0.11.0->langsmith<0.1.0,>=0.0.38->langchain<0.0.304,>=0.0.303->embedchain)\n",
      "  Using cached iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Collecting pluggy<2.0,>=0.12 (from pytest>=7.0->pytest-subtests<0.12.0,>=0.11.0->langsmith<0.1.0,>=0.0.38->langchain<0.0.304,>=0.0.303->embedchain)\n",
      "  Obtaining dependency information for pluggy<2.0,>=0.12 from https://files.pythonhosted.org/packages/05/b8/42ed91898d4784546c5f06c60506400548db3f7a4b3fb441cba4e5c17952/pluggy-1.3.0-py3-none-any.whl.metadata\n",
      "  Downloading pluggy-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading embedchain-0.0.92-py3-none-any.whl (117 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading chromadb-0.4.16-py3-none-any.whl (496 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m496.1/496.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp311-cp311-macosx_11_0_arm64.whl (198 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.7/198.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.0.303-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.2.0-py3-none-any.whl (219 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.9/219.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading posthog-3.0.2-py2.py3-none-any.whl (37 kB)\n",
      "Using cached youtube_transcript_api-0.6.1-py3-none-any.whl (24 kB)\n",
      "Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading kubernetes-28.1.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.0.62-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.16.1-cp311-cp311-macosx_11_0_arm64.whl (6.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading opentelemetry_api-1.21.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.21.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.21.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_proto-1.21.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.21.0-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.3/105.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.42b0-py3-none-any.whl (36 kB)\n",
      "Downloading overrides-7.4.0-py3-none-any.whl (17 kB)\n",
      "Downloading pulsar_client-3.3.0-cp311-cp311-macosx_10_15_universal2.whl (10.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Using cached typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Downloading importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading httptools-0.6.1-cp311-cp311-macosx_10_9_universal2.whl (145 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.9/145.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
      "Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Downloading pytest_subtests-0.11.0-py3-none-any.whl (6.7 kB)\n",
      "Using cached starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "Downloading uvloop-0.19.0-cp311-cp311-macosx_10_9_universal2.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-0.21.0-cp311-cp311-macosx_11_0_arm64.whl (418 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m418.2/418.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading websocket_client-1.6.4-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-12.0-cp311-cp311-macosx_11_0_arm64.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.3/121.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytest-7.4.3-py3-none-any.whl (325 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.1/325.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
      "Downloading pluggy-1.3.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: pypika, monotonic, flatbuffers, zipp, wrapt, websockets, websocket-client, uvloop, uvicorn, typing-extensions, tenacity, pulsar-client, pluggy, overrides, opentelemetry-semantic-conventions, opentelemetry-proto, jsonpointer, iniconfig, importlib-resources, humanfriendly, httptools, contextlib2, chroma-hnswlib, bcrypt, youtube-transcript-api, watchfiles, typer, starlette, schema, pytest, posthog, opentelemetry-exporter-otlp-proto-common, jsonpatch, importlib-metadata, deprecated, coloredlogs, pytest-subtests, opentelemetry-api, onnxruntime, kubernetes, fastapi, opentelemetry-sdk, openai, langsmith, opentelemetry-exporter-otlp-proto-grpc, langchain, chromadb, embedchain\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.2.2\n",
      "    Uninstalling tenacity-8.2.2:\n",
      "      Successfully uninstalled tenacity-8.2.2\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.27.8\n",
      "    Uninstalling openai-0.27.8:\n",
      "      Successfully uninstalled openai-0.27.8\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.0.230\n",
      "    Uninstalling langchain-0.0.230:\n",
      "      Successfully uninstalled langchain-0.0.230\n",
      "Successfully installed bcrypt-4.0.1 chroma-hnswlib-0.7.3 chromadb-0.4.16 coloredlogs-15.0.1 contextlib2-21.6.0 deprecated-1.2.14 embedchain-0.0.92 fastapi-0.104.1 flatbuffers-23.5.26 httptools-0.6.1 humanfriendly-10.0 importlib-metadata-6.8.0 importlib-resources-6.1.1 iniconfig-2.0.0 jsonpatch-1.33 jsonpointer-2.4 kubernetes-28.1.0 langchain-0.0.303 langsmith-0.0.62 monotonic-1.6 onnxruntime-1.16.1 openai-1.2.0 opentelemetry-api-1.21.0 opentelemetry-exporter-otlp-proto-common-1.21.0 opentelemetry-exporter-otlp-proto-grpc-1.21.0 opentelemetry-proto-1.21.0 opentelemetry-sdk-1.21.0 opentelemetry-semantic-conventions-0.42b0 overrides-7.4.0 pluggy-1.3.0 posthog-3.0.2 pulsar-client-3.3.0 pypika-0.48.9 pytest-7.4.3 pytest-subtests-0.11.0 schema-0.7.5 starlette-0.27.0 tenacity-8.2.3 typer-0.9.0 typing-extensions-4.8.0 uvicorn-0.24.0.post1 uvloop-0.19.0 watchfiles-0.21.0 websocket-client-1.6.4 websockets-12.0 wrapt-1.15.0 youtube-transcript-api-0.6.1 zipp-3.17.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade embedchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from embedchain import Pipeline as App\n",
    "\n",
    "# Create a bot instance\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "briefcase_bot = App()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload a file to the bot\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 22:05:17,724 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-XYkVH0xO6d85gMdawR4qBbiZ', bytes=18126, created_at=1699499116, filename='Term Sheet (Customized).docx', object='file', purpose='assistants', status='processed', status_details=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.create(\n",
    "  file=open(\"/Users/ojas/Downloads/briefcase-app/briefcase-desktop-app/files/briefcase files/Term Sheet (Customized).docx\", \"rb\"),\n",
    "  purpose=\"assistants\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 22:47:17,855 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/assistants \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_8SEh8PReeOUhYNT6Qm4bEalt', created_at=1699501637, description=None, file_ids=['file-XYkVH0xO6d85gMdawR4qBbiZ'], instructions='You are a personal assistant to a CEO. You help answer questions, walkthrough scenarios & give advice. Unless otherwise specified, you provide succinct answers.', metadata={}, model='gpt-4-1106-preview', name='Personal Assistant', object='assistant', tools=[ToolRetrieval(type='retrieval')])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "my_assistant = client.beta.assistants.create(\n",
    "    instructions=\"You are a personal assistant to a CEO. You help answer questions, walkthrough scenarios & give advice. Unless otherwise specified, you provide succinct answers.\",\n",
    "    name=\"Personal Assistant\",\n",
    "    tools=[{\"type\": \"retrieval\"}],\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    file_ids=[\"file-XYkVH0xO6d85gMdawR4qBbiZ\"],\n",
    ")\n",
    "print(my_assistant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "assitant_id = \"asst_kxuzmpbEogyPktqxKcTvVSTN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 22:14:07,728 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/threads/runs \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "run = client.beta.threads.create_and_run(\n",
    "  assistant_id=my_assistant.id,\n",
    "  thread={\n",
    "    \"messages\": [\n",
    "      {\"role\": \"user\", \"content\": \"How much am I diluting in this round of funding?\"}\n",
    "    ]\n",
    "  }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thread_hvNQMOSz7MjtFEAOhBpG7lY2'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 22:16:18,806 - httpx - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_hvNQMOSz7MjtFEAOhBpG7lY2/runs/run_YoxvPXwMn7ziZf9qqOU2p53t \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(id='run_YoxvPXwMn7ziZf9qqOU2p53t', assistant_id='asst_kxuzmpbEogyPktqxKcTvVSTN', cancelled_at=None, completed_at=1699499651, created_at=1699499647, expires_at=None, failed_at=None, file_ids=['file-XYkVH0xO6d85gMdawR4qBbiZ'], instructions='You are a personal assistant to a CEO. You help answer questions, walkthrough scenarios & give advice.', last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=1699499648, status='completed', thread_id='thread_hvNQMOSz7MjtFEAOhBpG7lY2', tools=[ToolAssistantToolsRetrieval(type='retrieval')])\n"
     ]
    }
   ],
   "source": [
    "ret_run = client.beta.threads.runs.retrieve(\n",
    "  thread_id=run.thread_id,\n",
    "  run_id=run.id,\n",
    ")\n",
    "print(ret_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 22:17:01,302 - httpx - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_hvNQMOSz7MjtFEAOhBpG7lY2 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_hvNQMOSz7MjtFEAOhBpG7lY2', created_at=1699499647, metadata={}, object='thread')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "my_thread = client.beta.threads.retrieve(run.thread_id)\n",
    "print(my_thread)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 22:18:05,511 - httpx - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_hvNQMOSz7MjtFEAOhBpG7lY2/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ThreadMessage(id='msg_msxFky03dEOFs4BvsZP9yTDI', assistant_id='asst_kxuzmpbEogyPktqxKcTvVSTN', content=[MessageContentText(text=Text(annotations=[], value=\"In this round of funding, you're diluting by 9% as specified in the term sheet, with up to $6,523,892 million being invested by Venture Capital LP, which will own 9% of Briefcase Inc. after the financing is complete. This is based on the post-money valuation since it states that the investor will own 9% of the company post-financing.\"), type='text')], created_at=1699499650, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_YoxvPXwMn7ziZf9qqOU2p53t', thread_id='thread_hvNQMOSz7MjtFEAOhBpG7lY2'), ThreadMessage(id='msg_3KRsXiIL5dd5MLDyLsnd9E59', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='How much am I diluting in this round of funding?'), type='text')], created_at=1699499647, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_hvNQMOSz7MjtFEAOhBpG7lY2')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "thread_messages = client.beta.threads.messages.list(run.thread_id)\n",
    "print(thread_messages.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 22:37:22,153 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/threads/thread_hvNQMOSz7MjtFEAOhBpG7lY2/messages \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "thread_message = client.beta.threads.messages.create(\n",
    "  run.thread_id,\n",
    "  role=\"user\",\n",
    "  content=\"Cool, and what if I had the similar terms for the next few rounds? How much would I have diluted by Series B?\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 22:43:07,511 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/threads/thread_hvNQMOSz7MjtFEAOhBpG7lY2/runs \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=run.thread_id,\n",
    "  assistant_id=my_assistant.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 22:44:59,965 - httpx - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_hvNQMOSz7MjtFEAOhBpG7lY2/runs/run_BKMFfJ3VkBRiMXoaSnxqYl5f \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(id='run_BKMFfJ3VkBRiMXoaSnxqYl5f', assistant_id='asst_kxuzmpbEogyPktqxKcTvVSTN', cancelled_at=None, completed_at=1699501398, created_at=1699501387, expires_at=None, failed_at=None, file_ids=['file-XYkVH0xO6d85gMdawR4qBbiZ'], instructions='You are a personal assistant to a CEO. You help answer questions, walkthrough scenarios & give advice.', last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=1699501387, status='completed', thread_id='thread_hvNQMOSz7MjtFEAOhBpG7lY2', tools=[ToolAssistantToolsRetrieval(type='retrieval')])\n"
     ]
    }
   ],
   "source": [
    "ret_run = client.beta.threads.runs.retrieve(\n",
    "  thread_id=run.thread_id,\n",
    "  run_id=run.id,\n",
    ")\n",
    "print(ret_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 22:45:13,733 - httpx - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_hvNQMOSz7MjtFEAOhBpG7lY2/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ThreadMessage(id='msg_dyg5ZxgmgBVIVToLCrvAWFDK', assistant_id='asst_kxuzmpbEogyPktqxKcTvVSTN', content=[MessageContentText(text=Text(annotations=[], value=\"To accurately calculate your total dilution by Series B, I would need to know the specifics of both the current funding round (which we know involves a 9% dilution) and any subsequent rounds, including the amount being raised and the valuation of the company during each round. \\n\\nWith the information from the current round, we can establish a baseline for your ownership. Assuming you own 100% of the company before this round, after the current round, you would own 91%. For subsequent rounds, you would need to provide the terms of each round, including the percentage dilution expected for each.\\n\\nLet's do a hypothetical calculation to illustrate how the dilution would compound if you had two more rounds with similar terms:\\n\\n- **After Series A (current round):** You are diluted by 9%, so you retain 91% ownership.\\n- **After Series B round:** If you were to dilute another 9%, you would then own 91% of the remaining 91% of your ownership stake. \\n\\nThis simple formula can be used: `remaining_ownership = current_ownership * (1 - dilution_rate)`.\\n\\nFor Series B, the calculation would be:\\n`remaining_ownership = 91% * (1 - 9%) = 91% * 91% ≈ 82.81%`.\\n\\nSo after two rounds of 9% dilution each, you would own approximately 82.81% of the company. If there were intervening events, such as options pool expansions or issuance of new equity, this would affect your ownership percentage, requiring us to adjust the calculation accordingly.\\n\\nIf you have the term sheets or any details for the hypothetical next round(s), please provide them so we can calculate the dilution more precisely.\"), type='text')], created_at=1699501388, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_BKMFfJ3VkBRiMXoaSnxqYl5f', thread_id='thread_hvNQMOSz7MjtFEAOhBpG7lY2'), ThreadMessage(id='msg_NvrtfGx7dtam7JqoUdvmLVjJ', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='Cool, and what if I had the similar terms for the next few rounds? How much would I have diluted by Series B?'), type='text')], created_at=1699501042, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_hvNQMOSz7MjtFEAOhBpG7lY2'), ThreadMessage(id='msg_msxFky03dEOFs4BvsZP9yTDI', assistant_id='asst_kxuzmpbEogyPktqxKcTvVSTN', content=[MessageContentText(text=Text(annotations=[], value=\"In this round of funding, you're diluting by 9% as specified in the term sheet, with up to $6,523,892 million being invested by Venture Capital LP, which will own 9% of Briefcase Inc. after the financing is complete. This is based on the post-money valuation since it states that the investor will own 9% of the company post-financing.\"), type='text')], created_at=1699499650, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_YoxvPXwMn7ziZf9qqOU2p53t', thread_id='thread_hvNQMOSz7MjtFEAOhBpG7lY2'), ThreadMessage(id='msg_3KRsXiIL5dd5MLDyLsnd9E59', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='How much am I diluting in this round of funding?'), type='text')], created_at=1699499647, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_hvNQMOSz7MjtFEAOhBpG7lY2')]\n"
     ]
    }
   ],
   "source": [
    "thread_messages = client.beta.threads.messages.list(run.thread_id)\n",
    "print(thread_messages.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To accurately calculate your total dilution by Series B, I would need to know the specifics of both the current funding round (which we know involves a 9% dilution) and any subsequent rounds, including the amount being raised and the valuation of the company during each round. \\n\\nWith the information from the current round, we can establish a baseline for your ownership. Assuming you own 100% of the company before this round, after the current round, you would own 91%. For subsequent rounds, you would need to provide the terms of each round, including the percentage dilution expected for each.\\n\\nLet's do a hypothetical calculation to illustrate how the dilution would compound if you had two more rounds with similar terms:\\n\\n- **After Series A (current round):** You are diluted by 9%, so you retain 91% ownership.\\n- **After Series B round:** If you were to dilute another 9%, you would then own 91% of the remaining 91% of your ownership stake. \\n\\nThis simple formula can be used: `remaining_ownership = current_ownership * (1 - dilution_rate)`.\\n\\nFor Series B, the calculation would be:\\n`remaining_ownership = 91% * (1 - 9%) = 91% * 91% ≈ 82.81%`.\\n\\nSo after two rounds of 9% dilution each, you would own approximately 82.81% of the company. If there were intervening events, such as options pool expansions or issuance of new equity, this would affect your ownership percentage, requiring us to adjust the calculation accordingly.\\n\\nIf you have the term sheets or any details for the hypothetical next round(s), please provide them so we can calculate the dilution more precisely.\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread_messages.data[0].content[0].text.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  How much will I dilute in this round of funding?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 23:23:41,464 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/threads/runs \"HTTP/1.1 200 OK\"\n",
      "2023-11-08 23:23:43,058 - httpx - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_NZNXZH2qhuMpMjvpOV0yHOdX/runs/run_H4Rt3yDlYm5nu2NYF1sPkBO3 \"HTTP/1.1 200 OK\"\n",
      "2023-11-08 23:23:44,583 - httpx - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_NZNXZH2qhuMpMjvpOV0yHOdX/runs/run_H4Rt3yDlYm5nu2NYF1sPkBO3 \"HTTP/1.1 200 OK\"\n",
      "2023-11-08 23:23:47,128 - httpx - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_NZNXZH2qhuMpMjvpOV0yHOdX/runs/run_H4Rt3yDlYm5nu2NYF1sPkBO3 \"HTTP/1.1 200 OK\"\n",
      "2023-11-08 23:23:48,739 - httpx - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_NZNXZH2qhuMpMjvpOV0yHOdX/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Assistant:  In this round of funding, you will be diluting by 9% since the term sheet specifies that the lead investor, Venture Capital LP, will own 9% of the Company post-financing. The investment amount for this round is up to $6,523,892, and the company's pre-money valuation is set at $100 million.\n",
      "You:  Ok, and what will it look like if I had a similar terms next round? How much would I retain then?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 23:24:24,444 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/threads/thread_NZNXZH2qhuMpMjvpOV0yHOdX/messages \"HTTP/1.1 200 OK\"\n",
      "2023-11-08 23:24:25,179 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/threads/thread_NZNXZH2qhuMpMjvpOV0yHOdX/runs \"HTTP/1.1 200 OK\"\n",
      "2023-11-08 23:24:26,751 - httpx - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_NZNXZH2qhuMpMjvpOV0yHOdX/runs/run_xPUOeOlZozDQi8hVZOxyvNqO \"HTTP/1.1 200 OK\"\n",
      "2023-11-08 23:24:28,276 - httpx - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_NZNXZH2qhuMpMjvpOV0yHOdX/runs/run_xPUOeOlZozDQi8hVZOxyvNqO \"HTTP/1.1 200 OK\"\n",
      "2023-11-08 23:24:30,829 - httpx - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_NZNXZH2qhuMpMjvpOV0yHOdX/runs/run_xPUOeOlZozDQi8hVZOxyvNqO \"HTTP/1.1 200 OK\"\n",
      "2023-11-08 23:24:32,358 - httpx - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_NZNXZH2qhuMpMjvpOV0yHOdX/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Assistant:  To calculate your ownership after a subsequent round of funding with similar terms (9% dilution per round), you would apply the dilution percentage to your remaining ownership after this round. Here's the calculation:\n",
      "\n",
      "1. After this current round, you retain 91% of your company. Let's assume you start with 100% ownership.\n",
      "2. In the next round, if another 9% is given to new investors, you would dilute your remaining shares again. Therefore, you would retain 91% of your remaining 91% ownership.\n",
      "\n",
      "The calculation would be as follows:\n",
      "Current ownership after this round = 100% - 9% = 91%\n",
      "Ownership after next round with similar dilution = 91% * (1 - 9%) = 91% * 91%\n",
      "Ownership after next round = 82.81%\n",
      "\n",
      "So, you would retain approximately 82.81% of the company after a second round of funding with similar terms.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "assistant_id = \"asst_8SEh8PReeOUhYNT6Qm4bEalt\"\n",
    "\n",
    "user_input = input(\"You: \")\n",
    "print(\"You: \", user_input)\n",
    "\n",
    "run = client.beta.threads.create_and_run(\n",
    "    assistant_id=assistant_id,\n",
    "    thread={\n",
    "        \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": user_input}\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "time.sleep(1)\n",
    "ret_run = client.beta.threads.runs.retrieve(run_id=run.id, thread_id=run.thread_id)\n",
    "while ret_run.completed_at == None:\n",
    "    time.sleep(1)\n",
    "    ret_run = client.beta.threads.runs.retrieve(run_id=run.id, thread_id=run.thread_id)\n",
    "    time.sleep(1)\n",
    "\n",
    "thread_messages = client.beta.threads.messages.list(run.thread_id)\n",
    "print(\"Your Assistant: \", thread_messages.data[0].content[0].text.value)\n",
    "\n",
    "\n",
    "question_2 = input(\"You: \")\n",
    "print(\"You: \", question_2)\n",
    "thread_message_2 = client.beta.threads.messages.create(\n",
    "  run.thread_id,\n",
    "  role=\"user\",\n",
    "  content=question_2\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=run.thread_id,\n",
    "    assistant_id=assistant_id,\n",
    "    )\n",
    "\n",
    "time.sleep(1)\n",
    "ret_run = client.beta.threads.runs.retrieve(run_id=run.id, thread_id=run.thread_id)\n",
    "while ret_run.completed_at == None:\n",
    "    time.sleep(1)\n",
    "    ret_run = client.beta.threads.runs.retrieve(run_id=run.id, thread_id=run.thread_id)\n",
    "    time.sleep(1)\n",
    "\n",
    "thread_messages = client.beta.threads.messages.list(run.thread_id)\n",
    "print(\"Your Assistant: \", thread_messages.data[0].content[0].text.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It seems like your message was sent accidentally without any content. Could you please provide more details or let me know how I can assist you further?'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread_messages.data[0].content[0].text.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 11:28:45,952 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "2023-11-09 11:28:48,331 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "2023-11-09 11:28:50,618 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "2023-11-09 11:28:52,907 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "ein_file = client.files.create(\n",
    "  file=open(\"/Users/ojas/Downloads/briefcase-app/briefcase-desktop-app/files/briefcase files/EIN Letter (Customized).docx\", \"rb\"),\n",
    "  purpose=\"assistants\"\n",
    ")\n",
    "\n",
    "consulting_agreement = client.files.create(\n",
    "  file=open(\"/Users/ojas/Downloads/briefcase-app/briefcase-desktop-app/files/briefcase files/Amendment to Consulting Agreement  (Customized).docx\", \"rb\"),\n",
    "  purpose=\"assistants\"\n",
    ")\n",
    "\n",
    "\n",
    "by_laws = client.files.create(\n",
    "  file=open(\"/Users/ojas/Downloads/briefcase-app/briefcase-desktop-app/files/briefcase files/Bylaws (Customized).docx\", \"rb\"),\n",
    "  purpose=\"assistants\"\n",
    ")\n",
    "\n",
    "employee_incentive_plan = client.files.create(\n",
    "    file=open(\"/Users/ojas/Downloads/briefcase-app/briefcase-desktop-app/files/briefcase files/Equity Incentive Plan (customized).docx\", \"rb\"),\n",
    "    purpose=\"assistants\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file-u1TIy3PVyBeZpg6lLE84XQpG'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee_incentive_plan.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 12:20:00,085 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/assistants/asst_8SEh8PReeOUhYNT6Qm4bEalt \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "my_updated_assistant = client.beta.assistants.update(\n",
    "  \"asst_8SEh8PReeOUhYNT6Qm4bEalt\",\n",
    "  instructions=\"\"\"\n",
    "  You are a personal assistant to a CEO. \n",
    "  You help answer questions, walkthrough scenarios & give advice. \n",
    "  Unless otherwise specified, you very provide succinct, clear answers.\n",
    "  Assume you are always in spoken conversation with the CEO, write short, clear answers as if you were speaking to them.\n",
    "  \"\"\",\n",
    "    name=\"Personal Assistant\",\n",
    "    tools=[{\"type\": \"retrieval\"}],\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    file_ids=[\"file-XYkVH0xO6d85gMdawR4qBbiZ\", ein_file.id, consulting_agreement.id, by_laws.id, employee_incentive_plan.id],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  Look in teh docs for this cause im the only holder bside venture capitall llp after our last round, Fine, say I inrease the stock option pool by 10% more, given that we've only had the one round via Venture LLP, how much will I retain?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 12:37:02,449 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/threads/runs \"HTTP/1.1 200 OK\"\n",
      "2023-11-09 12:37:05,037 - httpx - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_1Q3t4BiwCzHwZ3AdqLbKUuWO/runs/run_UCxNsuHR6sYx1qafqD3p17GF \"HTTP/1.1 200 OK\"\n",
      "2023-11-09 12:37:07,579 - httpx - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_1Q3t4BiwCzHwZ3AdqLbKUuWO/runs/run_UCxNsuHR6sYx1qafqD3p17GF \"HTTP/1.1 200 OK\"\n",
      "2023-11-09 12:37:10,103 - httpx - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_1Q3t4BiwCzHwZ3AdqLbKUuWO/runs/run_UCxNsuHR6sYx1qafqD3p17GF \"HTTP/1.1 200 OK\"\n",
      "2023-11-09 12:37:12,628 - httpx - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_1Q3t4BiwCzHwZ3AdqLbKUuWO/runs/run_UCxNsuHR6sYx1qafqD3p17GF \"HTTP/1.1 200 OK\"\n",
      "2023-11-09 12:37:13,230 - httpx - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_1Q3t4BiwCzHwZ3AdqLbKUuWO/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Assistant:  To answer your question, I need specific information about the current equity structure of your company. You mentioned that you are the only holder besides Venture Capital LLP and that there has been one round of funding. To calculate your ownership percentage after increasing the stock option pool by 10%, I would typically need:\n",
      "\n",
      "1. The percentage of the company you currently own.\n",
      "2. The percentage of the company owned by Venture Capital LLP.\n",
      "3. The total number of shares currently issued.\n",
      "4. The details of the stock option pool before and after the 10% increase.\n",
      "\n",
      "Unfortunately, the files you've uploaded are not accessible with the tool I have. If you can provide the above information, I can help you calculate your retained ownership after the increase in the stock option pool.\n",
      "\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "assistant_id = \"asst_8SEh8PReeOUhYNT6Qm4bEalt\"\n",
    "\n",
    "user_input = input(\"You: \")\n",
    "if user_input.lower() == 'q':\n",
    "    print(\"Goodbye!\") \n",
    "\n",
    "print(\"You: \", user_input)\n",
    "\n",
    "run = client.beta.threads.create_and_run(\n",
    "    assistant_id=assistant_id,\n",
    "    thread={\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "time.sleep(2)\n",
    "ret_run = client.beta.threads.runs.retrieve(run_id=run.id, thread_id=run.thread_id)\n",
    "while ret_run.completed_at is None:\n",
    "    time.sleep(2)\n",
    "    ret_run = client.beta.threads.runs.retrieve(run_id=run.id, thread_id=run.thread_id)\n",
    "\n",
    "thread_messages = client.beta.threads.messages.list(run.thread_id)\n",
    "print(\"Your Assistant: \", thread_messages.data[0].content[0].text.value)\n",
    "\n",
    "while user_input != 'q':\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == 'q':\n",
    "        print(\"Goodbye!\") \n",
    "        break\n",
    "    print(\"You: \", user_input)\n",
    "    thread_message = client.beta.threads.messages.create(\n",
    "        run.thread_id,\n",
    "        role=\"user\",\n",
    "        content=user_input\n",
    "    )\n",
    "\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=run.thread_id,\n",
    "        assistant_id=assistant_id,\n",
    "    )\n",
    "\n",
    "    time.sleep(2)\n",
    "    ret_run = client.beta.threads.runs.retrieve(run_id=run.id, thread_id=run.thread_id)\n",
    "    while ret_run.completed_at is None:\n",
    "        time.sleep(2)\n",
    "        ret_run = client.beta.threads.runs.retrieve(run_id=run.id, thread_id=run.thread_id)\n",
    "\n",
    "    thread_messages = client.beta.threads.messages.list(run.thread_id)\n",
    "    print(\"Your Assistant: \", thread_messages.data[0].content[0].text.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id='run_YAdqgm0gWhPXdywJESJ0eV3s', assistant_id='asst_8SEh8PReeOUhYNT6Qm4bEalt', cancelled_at=None, completed_at=None, created_at=1699550929, expires_at=None, failed_at=1699550948, file_ids=['file-XYkVH0xO6d85gMdawR4qBbiZ', 'file-NtTTT5vhI8iwsoHUNwFmgdtF', 'file-tj3cVBg3WtjC996j67p9yW9g', 'file-jXB3ISefiWZlrh7QTrxTlOTH', 'file-u1TIy3PVyBeZpg6lLE84XQpG'], instructions='\\n  You are a personal assistant to a CEO. \\n  You help answer questions, walkthrough scenarios & give advice. \\n  Unless otherwise specified, you very provide succinct, clear answers.\\n  Assume you are always in spoken conversation with the CEO, write short, clear answers as if you were speaking to them.\\n  ', last_error=LastError(code='rate_limit_exceeded', message='Rate limit reached for gpt-4-1106-preview in organization org-SZxJ5vIi1COjYBz63J9kRgPm on tokens_usage_based per min: Limit 10000, Used 6415, Requested 4096. Please try again in 3.066s. Visit https://platform.openai.com/account/rate-limits to learn more.'), metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=1699550929, status='failed', thread_id='thread_XfGeTLVLUefyVGvO5U8QgiRG', tools=[ToolAssistantToolsRetrieval(type='retrieval')])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-XYkVH0xO6d85gMdawR4qBbiZ', bytes=18126, created_at=1699499116, filename='Term Sheet (Customized).docx', object='file', purpose='assistants', status='processed', status_details=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.retrieve('file-XYkVH0xO6d85gMdawR4qBbiZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
